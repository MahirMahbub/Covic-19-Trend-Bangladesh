{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# Any results you write to the current directory are saved as output.\n\nsimilar_weather = pd.read_csv(r'../input/similar-weather-country/Similar_Weather.csv', header=None)\nsimilar_weather_country = similar_weather.iloc[0:73,[1]]\nsimilar_weather_country = similar_weather_country.apply(lambda x: x.str.capitalize() )\n\nunique_similar_weather_country = similar_weather_country.drop_duplicates()\nprint(unique_similar_weather_country)\n\n# %%\nunique_similar_weather_country.to_csv(r\"Similar_Weather_98_Percent.csv\")\n\n\nsimilar_weather = pd.read_csv(r\"Similar_Weather_98_Percent.csv\")\n# %%\nconfirmed_cases = pd.read_csv(r\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_confirmed.csv\")\nconfirmed_cases_country_and_count = confirmed_cases.drop([\"Province/State\", \"Lat\", \"Long\"], axis = 1)\n# %%\nunique_countries =  confirmed_cases_country_and_count[\"Country/Region\"].unique()\n\n# %%\nwhole_country_data = confirmed_cases_country_and_count.groupby(\"Country/Region\").sum()\nwhole_country_data.to_csv(r\"accumulated_whole_country_data.csv\")\n\nsimilar_weather = pd.read_csv(r\"Similar_Weather_98_Percent.csv\", names=[\"Country/Region\"], header = None)\nsimilar_weather = similar_weather[similar_weather[\"Country/Region\"] != \"China\"]\nsimilar_weather = similar_weather[similar_weather[\"Country/Region\"] != \"Iran\"]\nwhole_country_data = pd.read_csv(r\"accumulated_whole_country_data.csv\")\n\n#%%\n\nsimilar_data = pd.merge(similar_weather , whole_country_data, how='left', on = \"Country/Region\")\nfinal_similar_data = similar_data.dropna()\n\nfinal_similar_data.to_csv(r\"weather_similar_confirmed.csv\")\n\n\n\nfrom tensorflow.keras.layers import LSTM, Dropout, Dense\nfrom tensorflow.keras import optimizers, Sequential\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range=(0,1))\n# %%\nfinal_similar_data = pd.read_csv(r\"weather_similar_confirmed.csv\")\n# %%\n#sc = MinMaxScaler(feature_range=(0,1))\ntest_bangladesh_data = final_similar_data.iloc[[0]]\ntrain_data = final_similar_data.iloc[1:]\n# %%\nTIME_STEPS = 5\nLABEL_STEPS = 2\nBATCH_SIZE = 36\nloop_go = final_similar_data.shape[1] - TIME_STEPS - LABEL_STEPS\nX_train = []\nY_train = []\nfor country_data in train_data.values:\n    full_sequence = country_data[2:]\n    for start in range(loop_go-1):\n        X_train.append(full_sequence[start:TIME_STEPS+start])\n        Y_train.append(full_sequence[TIME_STEPS+start: TIME_STEPS+start+LABEL_STEPS])\n\nX_train = np.array(X_train).reshape(564, 5, 1).astype(np.float64)\nY_train = np.array(Y_train).reshape(564, 2).astype(np.float64)\n\n# %%\n\n#, batch_input_shape=(12, 5, 1),\n\nmodel = Sequential()\nmodel.add(LSTM(units=100,return_sequences=True,input_shape=(X_train.shape[1], 1)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=100,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=100,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=100))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=2))\noptimizer = optimizers.RMSprop(lr=0.0005)\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\nmodel.fit(X_train,Y_train,epochs=100,validation_split=0.25, batch_size=BATCH_SIZE)\n# %%\n#\tBangladesh\t23.685\t90.3563\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t3\t3\t3\t3\t3\t3\t3\t5\t8\t10\t14\n\nx_ = np.array([ 3, 5, 8, 10, 14]).reshape(1,5, 1)\nprint(model.predict(x_))\n\ntest_full_sequence = test_bangladesh_data.values\n# %%\ntest_full_sequence = test_full_sequence.reshape(test_full_sequence.shape[1], 1)[2:]\ntest_full_sequence = np.append(test_full_sequence, [5, 8, 10]).astype(np.float64)\n\n#%%\nX_test = []\nY_test = []\nfor start in range(loop_go+3-1):\n    X_test.append(test_full_sequence[start:TIME_STEPS+start])\n    Y_test.append(test_full_sequence[TIME_STEPS+start: TIME_STEPS+start+LABEL_STEPS])\n# %%\nX_test = np.array(X_test).reshape(50, 5, 1).astype(np.float64)\n#Y_test = np.array(Y_test).reshape(48, 2).astype(np.float64)\npredicted = np.floor(model.predict(X_test))\nfirst_day = []\nsecond_day = []\nfor pred in predicted:\n    first_day.append(pred[0])\n    second_day.append(pred[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}